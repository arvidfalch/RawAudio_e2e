{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scaper\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import Thesis_models\n",
    "import Thesis_models_nonTime\n",
    "\n",
    "sr = 24000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not in order of the MultiLabelBinarizer, disregard the order\n",
    "DESED_classes = ['Alarm_bell_ringing', 'Blender', 'Cat', 'Dishes', 'Dog', 'Electric_shaver_toothbrush', 'Frying', 'Running_water', 'Speech', 'Vacuum_cleaner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels before MultiLabelBinarizer one row example: ['None']\n",
      "Labels before MultiLabelBinarizer second row example: ['None']\n",
      "Labels shape before reshape is (3840000, 11)\n",
      "Labels one row example: [0 0 0 0 0 0 0 1 0 0 0]\n",
      "Labels one row example: [0 0 0 0 0 0 0 1 0 0 0]\n",
      "(6000, 10, 4096, 1) (6000, 10, 64, 11)\n",
      "['Alarm_bell_ringing' 'Blender' 'Cat' 'Dishes' 'Dog'\n",
      " 'Electric_shaver_toothbrush' 'Frying' 'None' 'Running_water' 'Speech'\n",
      " 'Vacuum_cleaner']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scene_path = '/Volumes/Expansion/DESED/Dataset_Output_Folder/audio/train/synthetic21_train/soundscapes/'\n",
    "#uni_name = 'soundscape_unimodal' \n",
    "scene_size = sr*10\n",
    "\n",
    "# Create dict for labels\n",
    "\n",
    "#labels_dict = {'non-vehicle':0, 'cars':1, 'motorcycles':2, 'tanks':3, 'trucks':4}\n",
    "#labels_names = ['no_event','cars', 'motorcycles', 'tanks', 'trucks']\n",
    "\n",
    "def audio_input_shaper(path, available_ids):\n",
    "    audio_input = (np.zeros(1,10,4096,1))\n",
    "    for i in available_ids:\n",
    "        audio, _ = librosa.load(path + str(i)+'.wav', sr=sr, mono=True)\n",
    "        x = np.pad(audio, (2861,2898))\n",
    "        x = np.reshape(x, (6,10,4096,1))\n",
    "        audio_input = np.concatenate((audio_input, x), axis=0)\n",
    "\n",
    "    audio_input = audio_input[1,:]\n",
    "\n",
    "    return audio_input\n",
    "\n",
    "n_soundscapes = 1000\n",
    "\n",
    "#features = np.zeros((1,10,4096,1))\n",
    "#labels = np.zeros((1, 10, 1))\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for scns in range(n_soundscapes):\n",
    "    scene, _ = librosa.load(scene_path + str(scns) + '.wav', sr=sr, mono=True)\n",
    "    \n",
    "    x1 = np.pad(scene, (2861,2898))\n",
    "    x = np.reshape(x1, (6,10,4096,1))\n",
    "    features.append(x)\n",
    "    #features = np.concatenate((features, x), axis=0)\n",
    "\n",
    "    headers = ['onset', 'offset', 'label']\n",
    "    txt = pd.read_csv(scene_path + str(scns) + '.txt', sep='\\t',  names=headers, index_col=False)\n",
    "\n",
    "    # split scene in chunks for labels\n",
    "    chunk_size = 4096\n",
    "    time_step = 64\n",
    "    step_size = chunk_size//time_step\n",
    "    \n",
    "    # Iterating through the whole sound scene capturing labels\n",
    "    for i in range(0, x1.size, step_size):\n",
    "        labels_temp = []\n",
    "        for b, row in txt.iterrows():\n",
    "            onset = int(row['onset'])*sr\n",
    "            offset = int(row['offset'])*sr\n",
    "            if onset < (i+step_size) and offset > (i):\n",
    "                labels_temp.append(row['label'])\n",
    "            else:\n",
    "                pass    \n",
    "    \n",
    "        for label in labels_temp:\n",
    "            if label in DESED_classes:\n",
    "\n",
    "                pass\n",
    "            else:\n",
    "                labels_temp = ['None']\n",
    "        labels.append(labels_temp)\n",
    "        \n",
    "\n",
    "features_out = np.concatenate(features, axis=0)\n",
    "print('Labels before MultiLabelBinarizer one row example: {}'.format(labels[0]))\n",
    "print('Labels before MultiLabelBinarizer second row example: {}'.format(labels[1]))\n",
    "one_hot = MultiLabelBinarizer()\n",
    "labels = one_hot.fit_transform(labels) \n",
    "label_names = one_hot.classes_\n",
    "print('Labels shape before reshape is {}'.format(labels.shape))\n",
    "print('Labels one row example: {}'.format(labels[0]))\n",
    "print('Labels one row example: {}'.format(labels[1]))\n",
    "labels = np.reshape(labels, ((n_soundscapes*6),10, step_size, len(label_names)))\n",
    "\n",
    "print(features_out.shape, labels.shape)\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels one row example: [0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('Labels one row example: {}'.format(labels[3210,6,1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRNN_RAe2e = Thesis_models.CRNN(len(label_names), 128, [5, 2, 2], [64, 64], [32], 10, 4096, 128, 64, sr=sr, melspec=False)\n",
    "CRNN_RAe2e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 10, 4096, 1)]     0         \n",
      "                                                                 \n",
      " conv (TimeDistributed)      (None, 10, 4096, 128)     8320      \n",
      "                                                                 \n",
      " conv_activation (TimeDistri  (None, 10, 4096, 128)    0         \n",
      " buted)                                                          \n",
      "                                                                 \n",
      " conv_smoothing (TimeDistrib  (None, 10, 4096, 128)    16512     \n",
      " uted)                                                           \n",
      "                                                                 \n",
      " conv_smoothing_activation (  (None, 10, 4096, 128)    0         \n",
      " TimeDistributed)                                                \n",
      "                                                                 \n",
      " max_pooling (TimeDistribute  (None, 10, 64, 128)      0         \n",
      " d)                                                              \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 640, 128)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 640, 128)         98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " LSTM_1 (LSTM)               (None, 640, 64)           49408     \n",
      "                                                                 \n",
      " LSTM_2 (LSTM)               (None, 640, 64)           33024     \n",
      "                                                                 \n",
      " Dense_Xtra (Dense)          (None, 640, 32)           2080      \n",
      "                                                                 \n",
      " Dense_layer (Dense)         (None, 640, 11)           363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 208,523\n",
      "Trainable params: 208,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_RAe2e = Thesis_models.LSTM_backend_2(10, 4096, 128, 64, n_of_classes=len(label_names), frame_level_classification=False, output_dim=64, melspec=False, sr=sr)\n",
    "LSTM_RAe2e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(CRNN_RAe2e, 'CRNN_RAe2e.png', show_shapes=True, show_layer_names=True, expand_nested=True, dpi=396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_Mel = Thesis_models.LSTM_backend(10, 4096, 128, 64, n_of_classes=len(label_names), frame_level_classification=False, output_dim=64, melspec=True, sr=sr)\n",
    "LSTM_Mel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 11:18:48.585070: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-18 11:18:48.585951: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer BiLSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer LSTM_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer LSTM_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 10, 4096, 1)]     0         \n",
      "                                                                 \n",
      " conv (TimeDistributed)      (None, 10, 4096, 128)     8320      \n",
      "                                                                 \n",
      " conv_activation (TimeDistri  (None, 10, 4096, 128)    0         \n",
      " buted)                                                          \n",
      "                                                                 \n",
      " conv_smoothing (TimeDistrib  (None, 10, 4096, 128)    16512     \n",
      " uted)                                                           \n",
      "                                                                 \n",
      " conv_smoothing_activation (  (None, 10, 4096, 128)    0         \n",
      " TimeDistributed)                                                \n",
      "                                                                 \n",
      " max_pooling (TimeDistribute  (None, 10, 64, 128)      0         \n",
      " d)                                                              \n",
      "                                                                 \n",
      " BiLSTM (TimeDistributed)    (None, 10, 64, 128)       98816     \n",
      "                                                                 \n",
      " LSTM1 (TimeDistributed)     (None, 10, 64, 64)        49408     \n",
      "                                                                 \n",
      " LSTM2 (TimeDistributed)     (None, 10, 64, 64)        33024     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 10, 64, 32)       2080      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 10, 64, 11)       363       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 208,523\n",
      "Trainable params: 208,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "LSTM_RAe2e = Thesis_models.LSTM_backend(10, 4096, 128, 64, n_of_classes=len(label_names), frame_level_classification=False, output_dim=64, melspec=False, sr=sr)\n",
    "LSTM_RAe2e.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(LSTM_Mel, 'LSTM_Mel.png', show_shapes=True, show_layer_names=True, expand_nested=True, dpi=396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 10, 4096, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "# forgot the random seed here so the +10 epoch evals are no good...\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(features_out, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(feat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 640, 11)\n"
     ]
    }
   ],
   "source": [
    "#  Run this cell if using RNN layers which are not timedistributed (LSTM_backend_2)\n",
    "\n",
    "lab_train_ = np.reshape(lab_train, (lab_train.shape[0],(lab_train.shape[1]*lab_train.shape[2]),len(label_names)))\n",
    "print(lab_train_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 00:27:08.720977: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3840/3840 [==============================] - 9295s 2s/step - loss: 0.1917 - accuracy: 0.5366 - val_loss: 0.1848 - val_accuracy: 0.5480\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For LSTM_backend_2 set batch size to 1. For all others batchsize = 10\n",
    "callback_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "history = LSTM_RAe2e.fit(\n",
    "    feat_train,\n",
    "    lab_train_,\n",
    "    validation_split=0.2,\n",
    "    #class_weight= {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.5, 4: 1.0},\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    epochs=1,\n",
    "    callbacks = [callback_stop]\n",
    "    \n",
    ")\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 640, 11)\n",
      "38/38 [==============================] - 391s 10s/step - loss: 0.1895 - accuracy: 0.5547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18951570987701416, 0.5546810030937195]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_test_ = np.reshape(lab_test, (lab_test.shape[0],(lab_test.shape[1]*lab_test.shape[2]),len(label_names)))\n",
    "print(lab_test_.shape)\n",
    "#feat_test_ = np.reshape(feat_test, (120,4096,1))\n",
    "#lab_test_ = np.reshape(lab_test, (120,64,5))\n",
    "\n",
    "LSTM_RAe2e.evaluate(feat_test, lab_test_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CRNN_Rafe 1 epoch 100 soundscapes (approx 12 minutes): loss: 0.2611 - accuracy: 0.3840\n",
    "* CRNN_RAe2e 1 ep 100sc (fixed LR, rnns:[64,64]): [0.2245444357395172, 0.4411458373069763]\n",
    "* LSTM_Rafe 1 epoch 100 soundscapes (approx 9 min): loss: 0.2174 - accuracy: 0.5179\n",
    "* LSTM RAe2e 1 ep 100s (fixed LR no sched) : loss: 0.2451 - accuracy: 0.4411\n",
    "* LSTM_mel 10 epochs 100 soundscapes (approx 7s pr epoch): loss: 0.2120 - accuracy: 0.4411 (Didn't seem to learn, loss decreased but accuracy remained the same)\n",
    "* CRNN_Mel 10 epochs 100 soundscapes (approx 2:30 min pr epoch): loss: 0.2177 - accuracy: 0.4411 (Didn't seem to learn. Guess the log mels are blank...)\n",
    "* CRNN_Mel 2 eps 100s (mels flipped 90 degrees): loss: 0.2165 - accuracy: 0.4411\n",
    "\n",
    "NO TIME DISTRIBUTION TESTS:\n",
    "* LSTM_RAe2e 10 epochs (10 soundscapes)(1 minute each) shuffle=True: [0.1243598461151123, 0.4678385555744171]\n",
    "* LSTM_RAe2e 10 epochs (10 soundscapes) shuffle=False: [0.15079300105571747, 0.4694010317325592] (Did not \"learn\", loss and accuracy almost identical all epochs)\n",
    "\n",
    "TIME DIST ONLY ON FRONTEND:\n",
    "* LSTM_RAe2e 1 epoch 100 soundscapes (15 min): loss: 0.2130 - accuracy: 0.4411\n",
    "* LSTM RAe2e 1 ep 1000 soundscapes (2 hours+):  loss: 0.1895 - accuracy: 0.5547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 07:55:31.541654: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/arvidfalch/Documents/Thesis/Idfrontend2/RAe2e/Models/1epoch_LSTM_RAe2e_notime_rnns_1000sc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x2849dc130> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x2849dca30> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x2898b1c40> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x2849e75b0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/arvidfalch/Documents/Thesis/Idfrontend2/RAe2e/Models/'\n",
    "model_description = '1epoch_LSTM_RAe2e_notime_rnns_1000sc'\n",
    "tf.keras.models.save_model(LSTM_RAe2e, path + model_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('1d5epochs2classesscraper_new_metrics_binaryc_loss')\n",
    "import librosa\n",
    "#path = '/Users/arvidfalch/repos/scaper_test/soundscapes/soundscape_unimodal7.wav'\n",
    "# stab\n",
    "#path = '/Users/arvidfalch/Desktop/BLLTImpt_Bullets_Impact_Body_Thump_Soundly_SND6360.wav'\n",
    "# tanks\n",
    "#path = '/Users/arvidfalch/Desktop/NoCatID_War_Heavy_Trucks_Passing_By_Close_Multiple_Multiple_Heavy_Trucks_Pass_0001_by_JoniHeinonen_Id_161880_JoniHeinonen_None.wav'\n",
    "#path = '/Users/arvidfalch/repos/sq/machine-learning-data/benchmark/dvc-machine-learning-vehicle-data/2021-12-14_Rena_Panzerwagen_hx128ip-00053/2021-12-14T11.09.34UTC_to_2021-12-14T11.10.32UTC_3c2be265/gain_39dB/label_type_track_0.wav'\n",
    "\n",
    "# Cars\n",
    "#path = '/Users/arvidfalch/repos/sq/machine-learning-data/benchmark/dvc-machine-learning-vehicle-data/2021-05-10 car record session us/Sqbundles/2021-05-10T20.23.13UTC_Unknown_US_HX128IP-00014_sounds of things.vehicle.motor vehicle (road).car_from_0.00s_to_3.85s/gain_39dB/label_type_track_0.wav'\n",
    "#path = '/Users/arvidfalch/repos/sq/machine-learning-data/benchmark/dvc-machine-learning-vehicle-data/2022-07-01_Gaustad_Oslo/2022-07-01T08.54.09UTC_to_2022-07-01T08.54.17UTC_5b95032d/gain_39dB/label_type_track_0.wav'\n",
    "# Deep bass\n",
    "#path = '/Users/arvidfalch/Desktop/DSGNRmbl_Designed_Rumble_Bass_Hit_Soundly_SND42461.wav'\n",
    "#path = '/Users/arvidfalch/Desktop/NoCatID_Sweep02_by_833_45_Id_9370_833_45_None.wav'\n",
    "#path = '/Users/arvidfalch/Desktop/NoCatID_Long_Cinematic_Sweep_by_stair_Id_156862_stair_None.wav'\n",
    "#path = '/Users/arvidfalch/Desktop/stockhausen_synth_wav.wav'\n",
    "#path = '/Users/arvidfalch/repos/Vehicles/Air/Drones/Aircraft_Radio_Controlled_Drone_Start_Engines_Slow_Not_Lifting_Off_Then_Stop_Syma_X5SW_SND29303.wav'\n",
    "#path = '/Users/arvidfalch/repos/arvidfalch/Dataset2/2019-03-20_rangetest/2019-03-20T13.34.02UTC_Vestby_R128-1-00002_Rangetest - preflight_from_0.13s_to_38.97s/gain_39dB/label_type_track_2.wav'\n",
    "# drone\n",
    "#path = '/Users/arvidfalch/repos/scaper_test/foreground/drone/Drone112.wav'\n",
    "#path = '/Users/arvidfalch/repos/scaper_test/foreground/drone/Drone145.wav'\n",
    "# Chatting cafe\n",
    "path = '/Users/arvidfalch/repos/Vehicles/Non-Vehicle/chatting cafes/Crowds_Walla_Hotel_Seminar_Room_Interior_Royal_Savoy_Lausanne_200_People_Talking_Business_Hours_SND63966.wav'\n",
    "# Drone upclose flying away\n",
    "#path = '/Users/arvidfalch/repos/scaper_test/foreground/drone/Drone150.wav'\n",
    "# Drone flying off far away\n",
    "#path = '/Users/arvidfalch/repos/scaper_test/foreground/drone/Drone154.wav'\n",
    "# drone\n",
    "#path = '/Users/arvidfalch/repos/scaper_test/soundscapes/soundscape_unimodal4.wav'\n",
    "# short drone\n",
    "#path = '/Users/arvidfalch/repos/scaper_test/soundscapes/soundscape_unimodal7.wav'\n",
    "# Very high frequencies\n",
    "#path = '/Users/arvidfalch/Desktop/NoCatID_Test_Tones_by_acclivity_Id_20680_acclivity_None.wav'\n",
    "# Freq Sweep\n",
    "#path = '/Users/arvidfalch/Desktop/NoCatID_Sine_Sweep_20_Hz_To_20_Khz_10_Seconds_by_reaktorplayer_Id_94224_reaktorplayer_None.wav'\n",
    "# Hydro\n",
    "#path = '/Users/arvidfalch/Desktop/point_az_0.5_el_-5.5.wav'\n",
    "\n",
    "signal, _ = librosa.load(path, sr = sr, mono=True)\n",
    "if signal.size < sr*10:\n",
    "  signal = np.pad(signal, (0, sr*10-signal.size+1))\n",
    "\n",
    "signal = signal[0:240001]\n",
    "x1 = np.pad(signal, (2861,2898))\n",
    "\n",
    "test = np.reshape(x1, (6,10,4096,1))\n",
    "layer_outputs = [layer.output for layer in model.layers[:]]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "activations = activation_model.predict(test)\n",
    "  \n",
    "layer_names = []\n",
    "  \n",
    "for layer in model.layers[:]:\n",
    "  layer_names.append(layer.name)\n",
    "print(layer_names)\n",
    "print(len(layer_names))\n",
    "print(layer_names[5])\n",
    "cont = activations[5]\n",
    "\n",
    "cont_ = np.array([])\n",
    "print(cont.shape)\n",
    "for q in range(cont.shape[0]):\n",
    "  for w in range(cont.shape[1]):\n",
    "    cont_ = np.append(cont_, cont[q,w,:])\n",
    "new_shape = int(cont.shape[0]*cont.shape[1]*cont.shape[2])\n",
    "cont_ = cont_.reshape((new_shape, 128))\n",
    "print(cont_.shape)\n",
    "cont_ = cont_.transpose([1,0])\n",
    "\n",
    "y = signal\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "yy = tf.squeeze(y)\n",
    "yy_pred = tf.squeeze(y_pred)\n",
    "\n",
    "import librosa.display\n",
    "x = signal\n",
    "hop_length = 256\n",
    "fig, ax = plt.subplots(figsize= (16,14), nrows=2, ncols=1, sharex=False)\n",
    "\n",
    "\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(x, hop_length=hop_length)),\n",
    "\n",
    "                            ref=np.max)\n",
    "\n",
    "librosa.display.specshow(D, y_axis='log', sr=sr, hop_length=hop_length,\n",
    "\n",
    "                         x_axis='time', ax=ax[0])\n",
    "\n",
    "\n",
    "ax[0] = plt.imshow(cont_, cmap ='viridis', interpolation='nearest', aspect='auto') \n",
    "\n",
    "ax[1].set(title='Log-frequency power spectrogram (upper) vs latent space learned representation')\n",
    "\n",
    "ax[1].label_outer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_test = np.array([activations[-1]])\n",
    "mean_array = np.round(np.mean(last_layer_test,axis=-2),2)\n",
    "print(mean_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1, 6, 10, 6)\n",
    "last_layer_array = np.array([activations[-1]])\n",
    "mean_array = np.round(np.mean(last_layer_array,axis=-2),2)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(np.abs(x1), alpha=0.2)\n",
    "plt.plot(np.repeat(np.ndarray.flatten(mean_array[:,:,:,0]),64*64))\n",
    "plt.plot(np.repeat(np.ndarray.flatten(mean_array[:,:,:,1]),64*64))\n",
    "plt.plot(np.repeat(np.ndarray.flatten(mean_array[:,:,:,2]),64*64))\n",
    "plt.plot(np.repeat(np.ndarray.flatten(mean_array[:,:,:,3]),64*64))\n",
    "plt.plot(np.repeat(np.ndarray.flatten(mean_array[:,:,:,4]),64*64))\n",
    "\n",
    "plt.legend(['audio', 'non_ground','cars', 'motorcycles', 'tanks', 'trucks'], loc='upper right')\n",
    "\n",
    "plt.axhline(0.5, c = 'black')\n",
    "\n",
    "plt.title('Prediction on audio file, mean of predictions (sigmoid 0-1) over 4096 samples windows')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "sf.write('chatter_from_bench.wav', x1, samplerate=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac1c3d485d1c559db8ec03f0d5193bd9544185f9b671cab351b342fa62eb33ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
