{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_42 (InputLayer)       [(None, 10, 64, 128)]     0         \n",
      "                                                                 \n",
      " time_distributed_315 (TimeD  (None, 10, 64, 128)      0         \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " BiLSTM (TimeDistributed)    (None, 10, 64, 128)       98816     \n",
      "                                                                 \n",
      " LSTM1 (TimeDistributed)     (None, 10, 64, 64)        49408     \n",
      "                                                                 \n",
      " LSTM2 (TimeDistributed)     (None, 10, 64, 64)        33024     \n",
      "                                                                 \n",
      " time_distributed_316 (TimeD  (None, 10, 64, 32)       2080      \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      " time_distributed_317 (TimeD  (None, 10, 64, 11)       363       \n",
      " istributed)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,691\n",
      "Trainable params: 183,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Conv1D, Conv2D, Dense, Activation, Concatenate, TimeDistributed, Lambda, Reshape, Dropout, Permute\n",
    "from keras.layers import Multiply, Add, UpSampling1D, MaxPooling1D, BatchNormalization, Bidirectional, LSTM, GRU, MaxPooling2D\n",
    "from Layers import Conv1D_local, Dense_local, SAAF, Conv1D_tied, Slice, LogMelSpectrogram\n",
    "\n",
    "\n",
    "\n",
    "sr = 24000\n",
    "\n",
    "def Frontend(batchsize_, win_length, filters, kernel_size_1, melspec=False, \n",
    "            output_dim=64, CRNN_output=False):\n",
    "    # CRNN_output adds channel dimension to the output (1 channel, data_format=channel last) \n",
    "    # for use in any Conv2D model\n",
    "    x = Input(shape=(batchsize_, win_length,1), name='input')\n",
    "\n",
    "    if melspec is False:\n",
    "        conv = Conv1D(filters, kernel_size_1, strides=1, padding='same',\n",
    "                        kernel_initializer='lecun_uniform', input_shape=(win_length, 1))\n",
    "        \n",
    "        activation_abs = Activation(K.abs, name='conv_activation') \n",
    "        # Original CAFx model uses softplus activation function\n",
    "        activation_sp = tf.keras.layers.ReLU()\n",
    "        max_pooling = MaxPooling1D(pool_size=win_length//output_dim, data_format='channels_last')\n",
    "\n",
    "        conv_smoothing = Conv1D_local(filters, kernel_size_1*2, strides=1, padding='same',\n",
    "                                    kernel_initializer='lecun_uniform')\n",
    "        \n",
    "        \n",
    "        X = TimeDistributed(conv, name='conv')(x)\n",
    "        X_abs = TimeDistributed(activation_abs, name='conv_activation')(X)\n",
    "        M = TimeDistributed(conv_smoothing, name='conv_smoothing')(X_abs)\n",
    "        M = TimeDistributed(activation_sp, name='conv_smoothing_activation')(M)\n",
    "        frontend_output = TimeDistributed(max_pooling, name='max_pooling')(M)\n",
    "    \n",
    "    elif melspec is True:\n",
    "        \n",
    "        X = TimeDistributed(tf.keras.layers.Lambda(lambda x: tf.squeeze(x, [-1])))(x)\n",
    "        #frontend_output = TimeDistributed(LogMelSpectrogram(sr, 512,64,128))(x)\n",
    "        X = TimeDistributed(tf.keras.layers.Lambda(lambda x: tf.pad(x, ([0,0],[int(256//2),int(256//2)]))))(X)\n",
    "        X = TimeDistributed(tf.keras.layers.Lambda(lambda x: tf.signal.stft(x, frame_length=256, frame_step=65,fft_length=256)))(X)\n",
    "        X = TimeDistributed(tf.keras.layers.Lambda(lambda x: tf.cast(tf.math.abs(x),dtype=tf.float32)))(X)\n",
    "        filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=128,\n",
    "            num_spectrogram_bins=256 // 2 + 1,\n",
    "            sample_rate=24000,\n",
    "            lower_edge_hertz=0,\n",
    "            upper_edge_hertz=sr//2)\n",
    "        X = TimeDistributed(tf.keras.layers.Lambda(lambda x: tf.linalg.matmul(x,\n",
    "                                     filterbank)))(X)\n",
    "        frontend_output = TimeDistributed(tf.keras.layers.Lambda(lambda x: 10*tf.cast(tf.experimental.numpy.log10(tf.keras.backend.clip(x**2,1e-10,None)),dtype=tf.float32)))(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if CRNN_output is True:\n",
    "        frontend_output = frontend_output[..., tf.newaxis]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model(inputs=[x], outputs=[frontend_output], name='Frontend')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def LSTM_backend(batchsize_, win_length, filters, kernel_size_1, n_of_classes, \n",
    "            melspec=False, output_dim=64, frame_level_classification=False, dense_units=32,\n",
    "            activation='tanh'):\n",
    "   \n",
    "    frontend = Frontend(batchsize_, win_length, filters, kernel_size_1, melspec=melspec, output_dim=output_dim)\n",
    "\n",
    "    bi_rnn = Bidirectional(LSTM(filters//2, activation=activation, stateful=False,\n",
    "                                 return_sequences=True, dropout=0.1,\n",
    "                                 recurrent_dropout=0.1, name='BiLSTM'))\n",
    "    bi_rnn1 = LSTM(filters//2, activation=activation, stateful=False,\n",
    "                                 return_sequences=True, dropout=0.1,\n",
    "                                 recurrent_dropout=0.1, name='LSTM_1')\n",
    "    if frame_level_classification is True:\n",
    "        bi_rnn2 = LSTM(filters//2, activation=activation, stateful=False,\n",
    "                                 return_sequences=False, dropout=0.1,\n",
    "                                 recurrent_dropout=0.1, name='LSTM_2')\n",
    "    elif frame_level_classification is False:\n",
    "        bi_rnn2 = LSTM(filters//2, activation=activation, stateful=False,\n",
    "                                 return_sequences=True, dropout=0.1,\n",
    "                                 recurrent_dropout=0.1, name='LSTM_2')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    Z = TimeDistributed(bi_rnn, name='BiLSTM')(frontend.output)\n",
    "    Z = TimeDistributed(bi_rnn1, name='LSTM1')(Z)\n",
    "    Z = TimeDistributed(bi_rnn2, name='LSTM2')(Z)\n",
    "    \n",
    "    z = TimeDistributed(keras.layers.Dense(dense_units, activation=activation, name='Dense_Xtra'))(Z)\n",
    "    y = TimeDistributed(keras.layers.Dense(n_of_classes, name='Dense_layer', activation='sigmoid'))(z)\n",
    "   \n",
    "\n",
    "    model = tf.keras.Model(inputs=[frontend.input], outputs=[y], name='LSTM')\n",
    "    \n",
    "    initial_learning_rate = 0.001\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=lr_schedule,)\n",
    "                    , loss='binary_crossentropy', metrics='accuracy') \n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "LSTM_RAe2e = LSTM_backend(10, 4096, 128, 64, n_of_classes=11, frame_level_classification=False, output_dim=64, melspec=True)\n",
    "LSTM_RAe2e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac1c3d485d1c559db8ec03f0d5193bd9544185f9b671cab351b342fa62eb33ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
